# Модуль `GizAI`

## Обзор

Модуль `GizAI` предоставляет асинхронный генератор для взаимодействия с API GizAI для получения ответов от AI-моделей. Он поддерживает стриминг ответов, системные сообщения и историю сообщений. Модуль использует `aiohttp` для асинхронных HTTP-запросов.

## Подробней

Модуль предназначен для интеграции с платформой GizAI и использования её моделей для генерации текста. Он форматирует запросы в соответствии с требованиями API GizAI и обрабатывает ответы, возвращая текст сгенерированный моделью.

## Классы

### `GizAI`

**Описание**: Класс `GizAI` является поставщиком асинхронного генератора, который взаимодействует с API GizAI. Он наследуется от `AsyncGeneratorProvider` и `ProviderModelMixin`.

**Наследует**:
- `AsyncGeneratorProvider`: Обеспечивает базовую функциональность для асинхронных генераторов.
- `ProviderModelMixin`: Добавляет поддержку выбора и управления моделями.

**Атрибуты**:
- `url` (str): URL главной страницы GizAI.
- `api_endpoint` (str): URL API для отправки запросов на генерацию текста.
- `working` (bool): Указывает, работает ли провайдер.
- `supports_stream` (bool): Указывает, поддерживает ли провайдер потоковую передачу данных. Всегда `False`.
- `supports_system_message` (bool): Указывает, поддерживает ли провайдер системные сообщения.
- `supports_message_history` (bool): Указывает, поддерживает ли провайдер историю сообщений.
- `default_model` (str): Модель, используемая по умолчанию (`chat-gemini-flash`).
- `models` (list[str]): Список поддерживаемых моделей.
- `model_aliases` (dict[str, str]): Псевдонимы моделей для совместимости.

#### Методы:
- `get_model(model: str) -> str`: Возвращает имя модели на основе псевдонима или использует модель по умолчанию.
- `create_async_generator(model: str, messages: Messages, proxy: str = None, **kwargs) -> AsyncResult`: Создает асинхронный генератор для получения ответов от API GizAI.

## Функции

### `get_model`

```python
    @classmethod
    def get_model(cls, model: str) -> str:
        """Возвращает имя модели на основе псевдонима или использует модель по умолчанию.
        Args:
            model (str): Имя модели или псевдоним.

        Returns:
            str: Имя модели.

        """
        ...
```

**Назначение**: Определяет, какую модель использовать, основываясь на входных данных. Если запрошенная модель находится в списке поддерживаемых моделей, она возвращается. Если модель имеет псевдоним, возвращается соответствующая модель. В противном случае возвращается модель по умолчанию.

**Параметры**:
- `model` (str): Имя модели, которое нужно проверить и, возможно, заменить на псевдоним.

**Возвращает**:
- `str`: Имя модели, которое будет использоваться.

**Как работает функция**:
1. **Проверка наличия в списке моделей**: Проверяет, входит ли `model` в список `cls.models`. Если да, возвращает `model`.
2. **Проверка псевдонима модели**: Если `model` нет в списке моделей, проверяет, есть ли она в `cls.model_aliases`. Если да, возвращает соответствующее значение из `cls.model_aliases`.
3. **Использование модели по умолчанию**: Если `model` нет ни в списке моделей, ни в псевдонимах, возвращает `cls.default_model`.

**Примеры**:

```python
GizAI.get_model('chat-gemini-flash')  # Возвращает 'chat-gemini-flash'
GizAI.get_model('gemini-1.5-flash')  # Возвращает 'chat-gemini-flash'
GizAI.get_model('unknown_model')     # Возвращает 'chat-gemini-flash'
```

### `create_async_generator`

```python
    @classmethod
    async def create_async_generator(
        cls,
        model: str,
        messages: Messages,
        proxy: str = None,
        **kwargs
    ) -> AsyncResult:
        """Создает асинхронный генератор для получения ответов от API GizAI.

        Args:
            model (str): Имя модели для использования.
            messages (Messages): Список сообщений для отправки.
            proxy (str, optional): Адрес прокси-сервера. По умолчанию `None`.
            **kwargs: Дополнительные аргументы.

        Returns:
            AsyncResult: Асинхронный генератор, возвращающий текст ответа.

        Raises:
            Exception: Если статус ответа не 201.
        """
        ...
```

**Назначение**: Функция `create_async_generator` создает асинхронный генератор, который отправляет сообщения в API GizAI и возвращает сгенерированный текст.

**Параметры**:
- `model` (str): Имя модели, которую нужно использовать для генерации текста.
- `messages` (Messages): Список сообщений, отправляемых в API.
- `proxy` (str, optional): Адрес прокси-сервера (если требуется). По умолчанию `None`.
- `**kwargs`: Дополнительные параметры, которые могут потребоваться для запроса.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, который выдает текст ответа.

**Вызывает исключения**:
- `Exception`: Если получен неожиданный статус ответа от API.

**Как работает функция**:

1. **Получение модели**: Сначала получает имя модели с помощью `cls.get_model(model)`, чтобы убедиться, что используется поддерживаемая модель или её псевдоним.
2. **Формирование заголовков**: Создает словарь `headers` с необходимыми HTTP-заголовками для запроса к API.
3. **Создание сессии**: Использует `aiohttp.ClientSession` для отправки асинхронных HTTP-запросов. `ClientSession` используется как контекстный менеджер.
4. **Формирование данных запроса**: Создает словарь `data`, содержащий модель и входные сообщения.  Структурирует сообщения в формате, требуемом API GizAI, различая системные сообщения от сообщений пользователя/бота.
5. **Отправка запроса**: Отправляет POST-запрос к `cls.api_endpoint` с использованием `session.post()`.  Включает `data` в формате JSON и использует `proxy`, если он указан.
6. **Обработка ответа**:
   - Если `response.status` равен 201, читает JSON-ответ и извлекает текст из поля `output`. Затем удаляет лишние пробелы с помощью `strip()` и выдает результат через `yield`.
   - Если `response.status` не равен 201, вызывает исключение `Exception` с сообщением об ошибке, включающим статус ответа и текст ответа.

**Примеры**:

```python
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is the capital of France?"}
]
async def main():
    async for response in GizAI.create_async_generator(model='chat-gemini-flash', messages=messages):
        print(response)

# Пример с использованием прокси:
async def main():
    async for response in GizAI.create_async_generator(model='chat-gemini-flash', messages=messages, proxy='http://proxy.example.com'):
        print(response)