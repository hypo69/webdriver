# Модуль для работы с Ollama

## Обзор

Модуль `Ollama` предоставляет класс `Ollama`, который используется для взаимодействия с локально установленной платформой Ollama для запуска и управления большими языковыми моделями. Этот класс наследуется от `OpenaiAPI` и предоставляет методы для получения списка доступных моделей и создания асинхронного генератора для взаимодействия с моделью.

## Подробней

Этот модуль позволяет взаимодействовать с Ollama API для выполнения задач, связанных с генерацией текста и другими задачами, которые могут быть выполнены большими языковыми моделями. Он использует переменные окружения `OLLAMA_HOST` и `OLLAMA_PORT` для определения адреса и порта сервера Ollama.

## Классы

### `Ollama`

**Описание**: Класс `Ollama` предоставляет интерфейс для взаимодействия с локально установленной платформой Ollama.

**Наследует**:
- `OpenaiAPI`: Наследует функциональность для работы с API, аналогичным OpenAI.

**Атрибуты**:
- `label` (str): Метка провайдера "Ollama".
- `url` (str): URL Ollama.
- `login_url` (Optional[str]): URL для логина (в данном случае `None`, так как не требуется).
- `needs_auth` (bool): Флаг, указывающий на необходимость аутентификации (в данном случае `False`).
- `working` (bool): Флаг, указывающий на работоспособность провайдера (в данном случае `True`).
- `models` (List[str]): Список доступных моделей, полученных от Ollama API.
- `default_model` (str): Модель по умолчанию.

**Методы**:
- `get_models()`: Получает список доступных моделей от Ollama API.
- `create_async_generator()`: Создает асинхронный генератор для взаимодействия с моделью.

## Функции

### `get_models`

```python
@classmethod
def get_models(cls, api_base: str = None, **kwargs):
    """
    Получает список доступных моделей от Ollama API.

    Args:
        api_base (str, optional): Базовый URL API. По умолчанию `None`.
        **kwargs: Дополнительные аргументы.

    Returns:
        List[str]: Список доступных моделей.
    """
    ...
```

**Назначение**: Получение списка доступных моделей от Ollama API. Если список моделей еще не был получен, он запрашивается с сервера Ollama и сохраняется в атрибуте `cls.models`.

**Параметры**:
- `api_base` (str, optional): Базовый URL API. Если `None`, используется значение из переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы.

**Возвращает**:
- `List[str]`: Список доступных моделей.

**Как работает функция**:

1. **Проверка наличия моделей**: Проверяется, был ли уже получен список моделей (`if not cls.models`).
2. **Определение URL**: Если `api_base` не указан, формируется URL на основе переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. Если `api_base` указан, он используется с заменой `/v1` на `/api/tags`.
3. **Запрос моделей**: Отправляется GET-запрос к Ollama API для получения списка моделей.
4. **Извлечение списка моделей**: Из JSON-ответа извлекается список моделей из ключа "models" и сохраняется в атрибуте `cls.models`. Также устанавливается модель по умолчанию (`cls.default_model`).
5. **Возврат списка моделей**: Возвращается список доступных моделей.

**Примеры**:

```python
# Пример вызова без указания api_base
models = Ollama.get_models()

# Пример вызова с указанием api_base
models = Ollama.get_models(api_base="http://localhost:11434/v1")
```

### `create_async_generator`

```python
@classmethod
def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    api_base: str = None,
    **kwargs
) -> AsyncResult:
    """
    Создает асинхронный генератор для взаимодействия с моделью.

    Args:
        model (str): Имя модели.
        messages (Messages): Список сообщений для отправки модели.
        api_base (str, optional): Базовый URL API. По умолчанию `None`.
        **kwargs: Дополнительные аргументы.

    Returns:
        AsyncResult: Асинхронный генератор для взаимодействия с моделью.
    """
    ...
```

**Назначение**: Создание асинхронного генератора для взаимодействия с моделью Ollama. Этот метод использует базовый класс `OpenaiAPI` для создания генератора.

**Параметры**:
- `model` (str): Имя модели.
- `messages` (Messages): Список сообщений для отправки модели.
- `api_base` (str, optional): Базовый URL API. Если `None`, используется значение из переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор для взаимодействия с моделью.

**Как работает функция**:

1. **Определение `api_base`**: Если `api_base` не указан, он формируется на основе переменных окружения `OLLAMA_HOST` и `OLLAMA_PORT`.
2. **Вызов метода базового класса**: Вызывается метод `create_async_generator` базового класса `OpenaiAPI` с указанными параметрами.

**Примеры**:

```python
# Пример вызова
messages = [{"role": "user", "content": "Hello, Ollama!"}]
generator = Ollama.create_async_generator(model="llama2", messages=messages)
```