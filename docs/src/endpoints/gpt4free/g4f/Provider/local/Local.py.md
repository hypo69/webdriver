# Модуль для работы с локальными моделями GPT4All

## Обзор

Модуль `Local.py` предоставляет интерфейс для взаимодействия с локальными моделями GPT4All. Он позволяет загружать и использовать модели непосредственно на устройстве, обеспечивая приватность и отсутствие зависимости от внешних серверов.

## Подробнее

Этот модуль является частью проекта `hypotez` и предназначен для интеграции локальных моделей в систему. Он проверяет наличие необходимых зависимостей, загружает список доступных моделей и предоставляет метод для создания запросов к выбранной модели.

## Классы

### `Local`

**Описание**: Класс `Local` предоставляет интерфейс для работы с локальными моделями GPT4All.

**Наследует**:
- `AbstractProvider`: Абстрактный класс для провайдеров моделей.
- `ProviderModelMixin`: Миксин для работы с моделями провайдера.

**Атрибуты**:
- `label` (str): Название провайдера - "GPT4All".
- `working` (bool): Флаг, указывающий на работоспособность провайдера (всегда `True`).
- `supports_message_history` (bool): Флаг, указывающий на поддержку истории сообщений (всегда `True`).
- `supports_system_message` (bool): Флаг, указывающий на поддержку системных сообщений (всегда `True`).
- `supports_stream` (bool): Флаг, указывающий на поддержку потоковой передачи данных (всегда `True`).
- `models` (List[str]): Список доступных моделей GPT4All.
- `default_model` (str): Модель по умолчанию.

**Методы**:
- `get_models()`: Возвращает список доступных моделей.
- `create_completion()`: Создает запрос к локальной модели и возвращает результат.

## Функции

### `get_models`

```python
@classmethod
def get_models(cls) -> list[str]:
    """
    Получает список доступных локальных моделей GPT4All.

    Args:
        cls: Ссылка на класс `Local`.

    Returns:
        list[str]: Список доступных моделей.

    Как работает функция:
    1. Проверяет, был ли уже загружен список моделей (`cls.models`).
    2. Если список моделей не был загружен, то загружает его с помощью функции `get_models()` из модуля `...locals.models`.
    3. Устанавливает первую модель из списка в качестве модели по умолчанию (`cls.default_model`).
    4. Возвращает список моделей.

    Схема работы функции:
    Проверка загруженного списка моделей
    │
    └──> Загрузка списка моделей из `get_models()`
         │
         └──> Установка модели по умолчанию
              │
              └──> Возврат списка моделей

    Примеры:
    ```python
    models = Local.get_models()
    print(models)
    ```
    """
```

### `create_completion`

```python
@classmethod
def create_completion(
    cls,
    model: str,
    messages: Messages,
    stream: bool,
    **kwargs
) -> CreateResult:
    """
    Создает запрос к локальной модели GPT4All и возвращает результат.

    Args:
        cls: Ссылка на класс `Local`.
        model (str): Название модели для запроса.
        messages (Messages): Список сообщений для отправки в модель.
        stream (bool): Флаг, указывающий на необходимость потоковой передачи данных.
        **kwargs: Дополнительные параметры для передачи в модель.

    Returns:
        CreateResult: Результат выполнения запроса.

    Raises:
        MissingRequirementsError: Если не установлены необходимые зависимости (пакет `gpt4all`).

    Как работает функция:
    1. Проверяет, установлены ли необходимые зависимости (пакет `gpt4all`).
    2. Если зависимости не установлены, вызывает исключение `MissingRequirementsError`.
    3. Если зависимости установлены, создает запрос к локальной модели с помощью функции `create_completion()` из модуля `...locals.provider`.
    4. Передает в функцию `create_completion()` название модели, список сообщений, флаг потоковой передачи данных и дополнительные параметры.
    5. Возвращает результат выполнения запроса.

    Схема работы функции:
    Проверка зависимостей
    │
    └──> Вызов исключения `MissingRequirementsError` (если зависимости не установлены)
         │
         └──> Создание запроса к локальной модели с помощью `LocalProvider.create_completion()`
              │
              └──> Возврат результата

    Примеры:
    ```python
    messages = [{"role": "user", "content": "Привет, как дела?"}]
    result = Local.create_completion(model="default", messages=messages, stream=False)
    print(result)
    ```
    """