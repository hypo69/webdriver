# Модуль HuggingFaceAPI

## Обзор

Модуль `HuggingFaceAPI` предназначен для взаимодействия с моделями Hugging Face для генерации текста. Он наследует функциональность от `OpenaiTemplate` и предоставляет методы для получения моделей, создания асинхронных генераторов и управления ключами API.

## Подробней

Этот модуль является частью проекта `hypotez` и отвечает за подключение к API Hugging Face для выполнения задач генерации текста. Он использует `StreamSession` для асинхронных запросов и обрабатывает ошибки, связанные с неверными моделями или необходимостью оплаты. Модуль также предоставляет механизм для получения списка доступных моделей и их соответствий.

## Классы

### `HuggingFaceAPI`

**Описание**: Класс для взаимодействия с API Hugging Face.

**Наследует**: `OpenaiTemplate`

**Атрибуты**:
- `label` (str): Метка провайдера "HuggingFace (Text Generation)".
- `parent` (str): Родительский провайдер "HuggingFace".
- `url` (str): URL для API Hugging Face.
- `api_base` (str): Базовый URL для API Hugging Face.
- `working` (bool): Указывает, работает ли провайдер.
- `needs_auth` (bool): Указывает, требуется ли аутентификация.
- `default_model` (str): Модель по умолчанию (`default_llama_model`).
- `default_vision_model` (str): Модель для работы с изображениями по умолчанию.
- `vision_models` (list[str]): Список моделей для работы с изображениями.
- `model_aliases` (dict[str, str]): Псевдонимы моделей.
- `fallback_models` (list[str]): Список запасных моделей.
- `provider_mapping` (dict[str, dict]): Словарь соответствий моделей провайдерам.

**Методы**:
- `get_model`: Получает модель.
- `get_models`: Получает список доступных моделей.
- `get_mapping`: Получает соответствие моделей провайдерам.
- `create_async_generator`: Создает асинхронный генератор для генерации текста.

## Функции

### `get_model`

```python
@classmethod
def get_model(cls, model: str, **kwargs) -> str:
    """
    Получает модель.

    Args:
        model (str): Имя модели.
        **kwargs: Дополнительные аргументы.

    Returns:
        str: Имя модели.

    Raises:
        ModelNotSupportedError: Если модель не поддерживается.
    """
    ...
```

**Назначение**: Получает имя модели, проверяя, поддерживается ли она, и возвращает его.

**Параметры**:
- `model` (str): Имя модели, которую необходимо получить.
- `**kwargs`: Дополнительные именованные аргументы, которые могут быть переданы.

**Возвращает**:
- `str`: Имя модели.

**Вызывает исключения**:
- `ModelNotSupportedError`: Если запрошенная модель не поддерживается.

**Как работает функция**:
1. Пытается получить модель с использованием метода `super().get_model(model, **kwargs)`.
2. Если возникает исключение `ModelNotSupportedError`, функция возвращает исходное имя модели.

```
     A
     |
     B
     |
     C
```

Где:
- `A`: Вызов `super().get_model` для получения модели.
- `B`: Обработка исключения `ModelNotSupportedError`.
- `C`: Возврат имени модели.

**Примеры**:

```python
# Пример 1: Получение поддерживаемой модели
model_name = HuggingFaceAPI.get_model("llama-2-7b")

# Пример 2: Получение неподдерживаемой модели
model_name = HuggingFaceAPI.get_model("unsupported-model")
```

### `get_models`

```python
@classmethod
def get_models(cls, **kwargs) -> list[str]:
    """
    Получает список доступных моделей.

    Args:
        **kwargs: Дополнительные аргументы.

    Returns:
        list[str]: Список доступных моделей.
    """
    ...
```

**Назначение**: Получает список доступных моделей из API Hugging Face или использует запасной список, если API недоступен.

**Параметры**:
- `**kwargs`: Дополнительные именованные аргументы, которые могут быть переданы.

**Возвращает**:
- `list[str]`: Список доступных моделей.

**Как работает функция**:
1. Проверяет, был ли уже получен список моделей (`cls.models`). Если да, возвращает его.
2. Если список моделей не был получен, функция делает запрос к API Hugging Face для получения списка моделей.
3. Если запрос успешен, извлекает идентификаторы моделей, у которых статус "live" и задача "conversational". Добавляет модели из `cls.provider_mapping.keys()`.
4. Если запрос не успешен, использует запасной список моделей (`cls.fallback_models`).
5. Возвращает список моделей.

```
     A
     |
     B
     |
     C --> D
     |       |
     |       E
     |
     F
```

Где:
- `A`: Проверка, был ли уже получен список моделей.
- `B`: Если список моделей был получен, возврат этого списка.
- `C`: Запрос к API Hugging Face для получения списка моделей.
- `D`: Извлечение идентификаторов моделей, у которых статус "live" и задача "conversational".
- `E`: Использование запасного списка моделей, если API недоступен.
- `F`: Возврат списка моделей.

**Примеры**:

```python
# Пример 1: Получение списка моделей
models = HuggingFaceAPI.get_models()
print(models)

# Пример 2: Последующий вызов для получения списка моделей из кэша
cached_models = HuggingFaceAPI.get_models()
```

### `get_mapping`

```python
@classmethod
async def get_mapping(cls, model: str, api_key: str = None):
    """
    Получает соответствие моделей провайдерам.

    Args:
        model (str): Имя модели.
        api_key (str, optional): Ключ API. По умолчанию None.

    Returns:
        dict: Соответствие моделей провайдерам.
    """
    ...
```

**Назначение**: Получает соответствие модели провайдеру из кэша или API Hugging Face.

**Параметры**:
- `model` (str): Имя модели, для которой нужно получить соответствие.
- `api_key` (str, optional): Ключ API для аутентификации. По умолчанию `None`.

**Возвращает**:
- `dict`: Соответствие модели провайдеру.

**Как работает функция**:
1. Проверяет, есть ли соответствие для данной модели в `cls.provider_mapping`. Если есть, возвращает его.
2. Если соответствие отсутствует, функция выполняет асинхронный HTTP-запрос к API Hugging Face для получения информации о модели.
3. Извлекает `inferenceProviderMapping` из полученных данных и сохраняет его в `cls.provider_mapping` для последующего использования.
4. Возвращает полученное соответствие модели провайдеру.

```
     A
     |
     B
     |
     C --> D --> E
     |
     F
```

Где:
- `A`: Проверка наличия соответствия модели в `cls.provider_mapping`.
- `B`: Если соответствие есть, возврат соответствия из `cls.provider_mapping`.
- `C`: Асинхронный HTTP-запрос к API Hugging Face для получения информации о модели.
- `D`: Извлечение `inferenceProviderMapping` из полученных данных.
- `E`: Сохранение соответствия в `cls.provider_mapping`.
- `F`: Возврат соответствия модели провайдеру.

**Примеры**:

```python
# Пример 1: Получение соответствия для модели из кэша
mapping = await HuggingFaceAPI.get_mapping("llama-2-7b")

# Пример 2: Получение соответствия для модели из API
mapping = await HuggingFaceAPI.get_mapping("new-model", api_key="your_api_key")
```

### `create_async_generator`

```python
@classmethod
async def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    api_base: str = None,
    api_key: str = None,
    max_tokens: int = 2048,
    max_inputs_lenght: int = 10000,
    media: MediaListType = None,
    **kwargs
):
    """
    Создает асинхронный генератор для генерации текста.

    Args:
        model (str): Имя модели.
        messages (Messages): Список сообщений.
        api_base (str, optional): Базовый URL API. По умолчанию None.
        api_key (str, optional): Ключ API. По умолчанию None.
        max_tokens (int, optional): Максимальное количество токенов. По умолчанию 2048.
        max_inputs_lenght (int, optional): Максимальная длина входных данных. По умолчанию 10000.
        media (MediaListType, optional): Список медиафайлов. По умолчанию None.
        **kwargs: Дополнительные аргументы.
    """
    ...
```

**Назначение**: Создает асинхронный генератор для генерации текста с использованием API Hugging Face.

**Параметры**:
- `model` (str): Имя модели для использования.
- `messages` (Messages): Список сообщений для передачи в модель.
- `api_base` (str, optional): Базовый URL API. По умолчанию `None`.
- `api_key` (str, optional): Ключ API для аутентификации. По умолчанию `None`.
- `max_tokens` (int, optional): Максимальное количество токенов в ответе. По умолчанию 2048.
- `max_inputs_lenght` (int, optional): Максимальная длина входных данных. По умолчанию 10000.
- `media` (MediaListType, optional): Список медиафайлов для передачи в модель. По умолчанию `None`.
- `**kwargs`: Дополнительные именованные аргументы, которые могут быть переданы.

**Как работает функция**:

1. **Определение модели**:
   - Если `model` не указана и `media` присутствует, устанавливает `model` в `cls.default_vision_model`.
   - Получает модель с помощью `cls.get_model(model)`.
2. **Получение соответствия провайдера**:
   - Получает соответствие модели провайдеру с помощью `cls.get_mapping(model, api_key)`.
   - Если соответствие не найдено, вызывает исключение `ModelNotSupportedError`.
3. **Итерация по провайдерам**:
   - Итерируется по списку провайдеров в `provider_mapping`.
   - Определяет `api_path` в зависимости от провайдера.
   - Устанавливает `api_base` для каждого провайдера.
   - Проверяет, что задача (`task`) соответствует "conversational". Если нет, вызывает `ModelNotSupportedError`.
   - Извлекает `providerId` из соответствия.
   - Передает информацию о провайдере через `yield ProviderInfo`.
4. **Создание и использование асинхронного генератора**:
   - Вызывает `super().create_async_generator` для создания асинхронного генератора.
   - Передает чанки (chunks) из генератора с помощью `yield chunk`.
   - Возвращает управление после завершения генерации.
5. **Обработка ошибок**:
   - Перехватывает исключение `PaymentRequiredError` и продолжает итерацию по провайдерам.
   - Если все провайдеры вызвали `PaymentRequiredError`, вызывает исключение `error`.

```
     A
     |
     B
     |
     C
     |
     D
     |
     E
     |
     F
     |
     G
```

Где:
- `A`: Определение модели и получение соответствия провайдера.
- `B`: Проверка наличия соответствия провайдера.
- `C`: Итерация по провайдерам.
- `D`: Определение `api_path` и установка `api_base`.
- `E`: Проверка типа задачи.
- `F`: Передача информации о провайдере через `yield ProviderInfo`.
- `G`: Создание и использование асинхронного генератора.

**Примеры**:

```python
# Пример 1: Создание асинхронного генератора для текстовой модели
messages = [{"role": "user", "content": "Hello, how are you?"}]
async_generator = HuggingFaceAPI.create_async_generator(model="llama-2-7b", messages=messages)

# Пример 2: Создание асинхронного генератора для модели обработки изображений
messages = [{"role": "user", "content": "Describe this image."}]
media = [{"url": "https://example.com/image.jpg", "type": "image/jpeg"}]
async_generator = HuggingFaceAPI.create_async_generator(model="vision-model", messages=messages, media=media)
```

### `calculate_lenght`

```python
def calculate_lenght(messages: Messages) -> int:
    """
    Вычисляет длину сообщений.

    Args:
        messages (Messages): Список сообщений.

    Returns:
        int: Суммарная длина сообщений.
    """
    ...
```

**Назначение**: Вычисляет суммарную длину сообщений, используемых в запросах к API Hugging Face.

**Параметры**:
- `messages` (Messages): Список сообщений, для которых нужно вычислить длину.

**Возвращает**:
- `int`: Суммарная длина всех сообщений в списке.

**Как работает функция**:
1. Использует генератор списков для итерации по каждому сообщению в списке `messages`.
2. Для каждого сообщения вычисляет длину содержимого (`message["content"]`) и добавляет 16.
3. Суммирует все вычисленные значения длин.

```
     A
     |
     B
```

Где:
- `A`: Итерация по списку сообщений.
- `B`: Вычисление длины каждого сообщения и суммирование.

**Примеры**:

```python
# Пример 1: Вычисление длины списка сообщений
messages = [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi there!"}
]
total_length = calculate_lenght(messages)
print(total_length)  # Вывод: 24 (5 + 16 + 9 + 16)