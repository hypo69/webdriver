# Модуль Lockchat
## Обзор

Модуль `Lockchat` представляет собой реализацию провайдера для взаимодействия с сервисом Lockchat. Он предоставляет функциональность для создания запросов к API Lockchat и получения ответов, поддерживая как потоковую передачу данных, так и работу с моделями GPT-3.5 Turbo и GPT-4. Модуль предназначен для использования в проектах, требующих интеграции с Lockchat для генерации текста.

## Подробнее

Модуль `Lockchat` является частью системы провайдеров, используемых для доступа к различным сервисам генерации текста. Он определяет URL, поддерживает потоковую передачу и указывает, какие модели GPT поддерживаются. Основная функциональность заключается в отправке запросов к API Lockchat и обработке ответов, включая поддержку потоковой передачи данных.

## Классы

### `Lockchat`

**Описание**: Класс `Lockchat` представляет собой провайдер для взаимодействия с сервисом Lockchat.

**Наследует**:
- `AbstractProvider`: Класс `Lockchat` наследует функциональность от абстрактного класса `AbstractProvider`, который определяет интерфейс для всех провайдеров в системе.

**Атрибуты**:
- `url` (str): URL-адрес API Lockchat. По умолчанию `"http://supertest.lockchat.app"`.
- `supports_stream` (bool): Флаг, указывающий на поддержку потоковой передачи данных. По умолчанию `True`.
- `supports_gpt_35_turbo` (bool): Флаг, указывающий на поддержку модели GPT-3.5 Turbo. По умолчанию `True`.
- `supports_gpt_4` (bool): Флаг, указывающий на поддержку модели GPT-4. По умолчанию `True`.

**Методы**:
- `create_completion`: Создает запрос к API Lockchat и возвращает результат.

## Функции

### `create_completion`

```python
    @staticmethod
    def create_completion(
        model: str,
        messages: list[dict[str, str]],
        stream: bool, **kwargs: Any) -> CreateResult:
        """ Функция создает запрос к API Lockchat для генерации текста на основе предоставленных параметров.

        Args:
            model (str): Идентификатор используемой модели.
            messages (list[dict[str, str]]): Список сообщений для передачи в API.
            stream (bool): Флаг, указывающий на использование потоковой передачи данных.
            **kwargs (Any): Дополнительные параметры запроса.

        Returns:
            CreateResult: Результат запроса к API Lockchat.

        Raises:
            requests.exceptions.HTTPError: Если HTTP запрос завершается с ошибкой.

        """
```

**Назначение**: Функция `create_completion` отправляет запрос к API Lockchat для генерации текста на основе предоставленных параметров, таких как модель, сообщения и настройки потоковой передачи.

**Параметры**:
- `model` (str): Идентификатор используемой модели.
- `messages` (list[dict[str, str]]): Список сообщений для передачи в API.
- `stream` (bool): Флаг, указывающий на использование потоковой передачи данных.
- `**kwargs` (Any): Дополнительные параметры запроса, такие как температура.

**Возвращает**:
- `CreateResult`: Результат запроса к API Lockchat.

**Вызывает исключения**:
- `requests.exceptions.HTTPError`: Если HTTP запрос завершается с ошибкой.

**Как работает функция**:

1. **Подготовка полезной нагрузки (payload)**: Функция извлекает значение температуры из `kwargs` или устанавливает значение по умолчанию 0.7. Затем формируется словарь `payload`, который включает температуру, сообщения, модель и флаг потоковой передачи.

2. **Формирование заголовков**: Создаются заголовки `headers`, включающие User-Agent.

3. **Отправка запроса к API**: Используется библиотека `requests` для отправки POST-запроса к API Lockchat с указанным URL, данными `payload` и заголовками `headers`. Устанавливается потоковая передача (`stream=True`).

4. **Обработка потока токенов**: Функция итерируется по строкам ответа, полученного от API.

5. **Обработка ошибок**: Проверяется наличие сообщения об ошибке, связанной с отсутствием модели `gpt-4`. В случае обнаружения ошибки, функция рекурсивно вызывает сама себя для повторной попытки.

6. **Извлечение содержимого**: Если в токене обнаружено ключевое слово `"content"`, токен декодируется из формата UTF-8, извлекается полезная нагрузка JSON, и извлекается содержимое из поля `"content"`.

7. **Генерация токенов**: Если содержимое извлечено успешно, оно передается в виде токена.

```
    Начало
    │
    ├──► Получение температуры из kwargs или установка значения по умолчанию
    │   temperature = kwargs.get("temperature", 0.7)
    │
    ├──► Формирование payload с температурой, сообщениями, моделью и флагом потоковой передачи
    │   payload = {"temperature": temperature, "messages": messages, "model": model, "stream": True}
    │
    ├──► Формирование заголовков User-Agent
    │   headers = {"user-agent": "ChatX/39 CFNetwork/1408.0.4 Darwin/22.5.0"}
    │
    ├──► Отправка POST-запроса к API Lockchat с потоковой передачей
    │   response = requests.post("http://supertest.lockchat.app/v1/chat/completions", json=payload, headers=headers, stream=True)
    │
    ├──► Итерация по строкам ответа
    │   for token in response.iter_lines():
    │
    ├──► Проверка на наличие ошибки "The model: `gpt-4` does not exist"
    │   if b"The model: `gpt-4` does not exist" in token:
    │   └──► Рекурсивный вызов create_completion для повторной попытки
    │
    ├──► Проверка на наличие "content" в токене
    │   if b"content" in token:
    │   └──► Извлечение содержимого из JSON
    │
    └──► Выдача токена
```

**Примеры**:

Пример 1: Создание запроса с использованием модели "gpt-3.5-turbo" и потоковой передачей.
```python
Lockchat.create_completion(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello"}], stream=True)
```

Пример 2: Создание запроса с указанием температуры.
```python
Lockchat.create_completion(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello"}], stream=True, temperature=0.9)