# Модуль Vercel

## Обзор

Модуль `Vercel` предоставляет реализацию для взаимодействия с моделями AI через API Vercel. Он позволяет создавать запросы к моделям, поддерживающим генерацию текста, таким как `gpt-3.5-turbo`, и получать потоковые ответы. Этот модуль предназначен для использования в проектах, требующих интеграции с AI-сервисами Vercel.

## Подробней

Модуль обеспечивает асинхронное взаимодействие с API Vercel, поддерживая потоковую передачу данных для эффективной обработки больших объемов текста. Он также включает механизм для получения anti-bot токена, необходимого для аутентификации запросов.

## Классы

### `Vercel`

**Описание**: Класс `Vercel` является реализацией интерфейса `AbstractProvider` и предоставляет методы для создания запросов к моделям AI Vercel.

**Наследует**: `AbstractProvider`

**Атрибуты**:
- `url` (str): URL для доступа к API Vercel.
- `working` (bool): Флаг, указывающий, работает ли провайдер.
- `supports_message_history` (bool): Флаг, указывающий, поддерживает ли провайдер историю сообщений.
- `supports_gpt_35_turbo` (bool): Флаг, указывающий, поддерживает ли провайдер модель `gpt-3.5-turbo`.
- `supports_stream` (bool): Флаг, указывающий, поддерживает ли провайдер потоковую передачу данных.

**Методы**:

- `create_completion(model: str, messages: Messages, stream: bool, proxy: str = None, **kwargs) -> CreateResult`

## Функции

### `create_completion`

```python
    @staticmethod
    def create_completion(
        model: str,
        messages: Messages,
        stream: bool,
        proxy: str = None,
        **kwargs
    ) -> CreateResult:
        """
        Создает запрос к API Vercel для получения завершения текста на основе предоставленных параметров.

        Args:
            model (str): Идентификатор модели AI для использования.
            messages (Messages): Список сообщений для отправки в модель.
            stream (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
            proxy (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
            **kwargs: Дополнительные параметры для передачи в API.

        Returns:
            CreateResult: Генератор токенов текста, возвращаемых моделью.

        Raises:
            MissingRequirementsError: Если отсутствует необходимый пакет `PyExecJS`.
            ValueError: Если указанная модель не поддерживается Vercel.

        Как работает функция:
            1. Проверяет наличие необходимого пакета `PyExecJS`. Если пакет отсутствует, вызывает исключение `MissingRequirementsError`.
            2. Проверяет, указана ли модель. Если модель не указана, использует модель `gpt-3.5-turbo` по умолчанию.
            3. Проверяет, поддерживается ли указанная модель. Если модель не поддерживается, вызывает исключение `ValueError`.
            4. Формирует заголовки запроса, включая anti-bot токен.
            5. Формирует данные запроса в формате JSON, включая идентификатор модели, сообщения и дополнительные параметры.
            6. Отправляет POST-запрос к API Vercel с использованием указанных заголовков, данных и параметров потоковой передачи.
            7. Обрабатывает ответ от API, итерируясь по содержимому и возвращая каждый токен текста.
        """
        ...
```

**Параметры**:

- `model` (str): Идентификатор модели AI для использования.
- `messages` (Messages): Список сообщений для отправки в модель.
- `stream` (bool): Флаг, указывающий, следует ли использовать потоковую передачу данных.
- `proxy` (str, optional): URL прокси-сервера для использования. По умолчанию `None`.
- `**kwargs`: Дополнительные параметры для передачи в API.

**Возвращает**:

- `CreateResult`: Генератор токенов текста, возвращаемых моделью.

**Вызывает исключения**:

- `MissingRequirementsError`: Если отсутствует необходимый пакет `PyExecJS`.
- `ValueError`: Если указанная модель не поддерживается Vercel.

**Внутренние функции**: Нет

**Как работает функция**:

```
Проверка PyExecJS --> Проверка модели --> Формирование заголовков и данных запроса --> Отправка POST-запроса --> Обработка ответа (генерация токенов)
```

**Примеры**:

Пример 1: Создание запроса с использованием модели по умолчанию и потоковой передачей данных.

```python
messages = [{"role": "user", "content": "Hello, how are you?"}]
result = Vercel.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True)
for token in result:
    print(token, end="")
```

Пример 2: Создание запроса с использованием прокси-сервера.

```python
messages = [{"role": "user", "content": "Tell me a joke."}]
result = Vercel.create_completion(model="gpt-3.5-turbo", messages=messages, stream=True, proxy="http://your_proxy:8080")
for token in result:
    print(token, end="")
```

### `get_anti_bot_token`

```python
def get_anti_bot_token() -> str:
    """
    Получает anti-bot токен, необходимый для аутентификации запросов к API Vercel.

    Returns:
        str: Anti-bot токен в формате base64.

    Как работает функция:
        1. Формирует заголовки запроса.
        2. Отправляет GET-запрос к API Vercel для получения данных, используемых для генерации токена.
        3. Декодирует ответ в формате base64 и загружает данные JSON.
        4. Формирует JavaScript-скрипт, используемый для генерации токена.
        5. Использует `execjs` для выполнения JavaScript-скрипта и получения токена.
        6. Формирует JSON с полученным токеном и данными.
        7. Кодирует JSON в формат base64 и возвращает результат.
    """
    ...
```

**Назначение**:
Функция `get_anti_bot_token` получает anti-bot токен, который необходим для аутентификации при запросах к API Vercel.

**Возвращает**:
- `str`: Anti-bot токен в формате base64.

**Как работает функция**:

```
Формирование заголовков запроса --> GET-запрос к API --> Декодирование base64 и загрузка JSON --> Формирование JavaScript-скрипта --> Выполнение JavaScript-скрипта --> Формирование JSON с токеном --> Кодирование в base64
```

**Примеры**:

```python
token = get_anti_bot_token()
print(f"Anti-bot token: {token}")
```

### `ModelInfo`

**Описание**: `ModelInfo` - это `TypedDict`, который используется для определения структуры данных, содержащей информацию о модели AI.

**Атрибуты**:
- `id` (str): Идентификатор модели.
- `default_params` (dict[str, Any]): Словарь, содержащий параметры по умолчанию для модели.

### `model_info`

**Описание**: `model_info` - это словарь, который содержит информацию о различных моделях AI, поддерживаемых Vercel.

**Тип**: `dict[str, ModelInfo]`

Пример использования:

```python
model_id = model_info['gpt-3.5-turbo']['id']
default_temperature = model_info['gpt-3.5-turbo']['default_params']['temperature']
```