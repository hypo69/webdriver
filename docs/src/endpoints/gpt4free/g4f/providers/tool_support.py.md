# Модуль поддержки инструментов (tool_support.py)

## Обзор

Модуль `tool_support.py` предназначен для обеспечения поддержки инструментов (tool) в асинхронных запросах к различным провайдерам моделей. Он предоставляет класс `ToolSupportProvider`, который позволяет использовать инструменты в запросах к моделям, таким как GPT-4. Модуль обрабатывает запросы с инструментами, форматирует их и возвращает результаты в нужном формате.

## Подробнее

Этот модуль является частью системы, которая позволяет использовать различные AI-модели через единый интерфейс. Он включает в себя поддержку передачи инструментов в запросах к моделям, что позволяет моделям выполнять определенные функции или действия на основе предоставленных инструментов.

## Классы

### `ToolSupportProvider`

**Описание**:
Класс `ToolSupportProvider` предоставляет функциональность для поддержки инструментов при взаимодействии с различными провайдерами моделей. Он наследуется от класса `AsyncGeneratorProvider`.

**Наследует**:
`AsyncGeneratorProvider` - обеспечивает базовую функциональность для асинхронных генераторов.

**Атрибуты**:
- `working` (bool): Флаг, указывающий на то, что провайдер находится в рабочем состоянии. По умолчанию `True`.

**Методы**:
- `create_async_generator`: Создает асинхронный генератор для обработки запроса с использованием инструментов.

## Функции

### `create_async_generator`

```python
@classmethod
async def create_async_generator(
    cls,
    model: str,
    messages: Messages,
    stream: bool = True,
    media: MediaListType = None,
    tools: list[str] = None,
    response_format: dict = None,
    **kwargs
) -> AsyncResult:
    """
    Создает асинхронный генератор для обработки запроса с использованием инструментов.

    Args:
        model (str): Имя модели для использования.
        messages (Messages): Список сообщений для отправки в модель.
        stream (bool, optional): Флаг, указывающий, использовать ли потоковую передачу. По умолчанию `True`.
        media (MediaListType, optional): Список медиафайлов для отправки в модель. По умолчанию `None`.
        tools (list[str], optional): Список инструментов для использования в запросе. По умолчанию `None`.
        response_format (dict, optional): Формат ответа, ожидаемый от модели. По умолчанию `None`.
        **kwargs: Дополнительные аргументы для передачи в провайдер модели.

    Returns:
        AsyncResult: Асинхронный генератор, который возвращает результаты обработки запроса.

    Raises:
        ValueError: Если передано больше одного инструмента.

    """
```

**Назначение**:
Функция `create_async_generator` создает и возвращает асинхронный генератор, который обрабатывает запросы к модели с использованием инструментов. Она отвечает за настройку провайдера, форматирование запроса и обработку ответа от модели.

**Параметры**:
- `cls`: Ссылка на класс `ToolSupportProvider`.
- `model` (str): Имя модели для использования. Может включать имя провайдера через `:`.
- `messages` (Messages): Список сообщений для отправки в модель.
- `stream` (bool, optional): Флаг, указывающий, использовать ли потоковую передачу. По умолчанию `True`.
- `media` (MediaListType, optional): Список медиафайлов для отправки в модель. По умолчанию `None`.
- `tools` (list[str], optional): Список инструментов для использования в запросе. По умолчанию `None`.
- `response_format` (dict, optional): Формат ответа, ожидаемый от модели. По умолчанию `None`.
- `**kwargs`: Дополнительные аргументы для передачи в провайдер модели.

**Возвращает**:
- `AsyncResult`: Асинхронный генератор, который возвращает результаты обработки запроса.

**Вызывает исключения**:
- `ValueError`: Если передано больше одного инструмента.

**Как работает функция**:

1.  **Разделение модели и провайдера**: Если в имени модели присутствует `:` , функция разделяет строку на имя провайдера и имя модели.
2.  **Получение модели и провайдера**: Использует функцию `get_model_and_provider` для получения объектов модели и провайдера на основе предоставленных аргументов.
3.  **Обработка инструментов**:
    *   Проверяет, что передан только один инструмент. Если передано больше одного, вызывает исключение `ValueError`.
    *   Если `response_format` не указан, устанавливает его в `{"type": "json"}`.
    *   Формирует список строк `lines`, включающий указание на формат JSON ответа и структуру параметров инструмента.
    *   Добавляет сформированные строки в начало списка сообщений `messages`.
4.  **Асинхронная генерация чанков**:
    *   Вызывает `provider.get_async_create_function()` для получения асинхронного генератора, который возвращает чанки данных от модели.
    *   Итерируется по чанкам, полученным от генератора:
        *   Если чанк является строкой, добавляет его в список `chunks`.
        *   Если чанк является объектом `Usage`, передает его дальше и устанавливает флаг `has_usage` в `True`.
        *   Если чанк является объектом `FinishReason`, сохраняет его в переменной `finish` и прерывает цикл.
        *   В противном случае передает чанк дальше.
5.  **Обработка результатов**:
    *   Если не было получено информации об использовании (`has_usage` is `False`), генерирует объект `Usage` на основе длины накопленных чанков.
    *   Объединяет все чанки в одну строку `chunks`.
    *   Если использовались инструменты, генерирует объект `ToolCalls` с информацией о вызове инструмента, включая имя функции и аргументы, отфильтрованные с помощью `filter_json`.
    *   Передает итоговые чанки.
6.  **Завершение**: Если был получен объект `FinishReason`, передает его.

**ASCII flowchart**:

```
    Начало
    ↓
    Разделение модели и провайдера
    ↓
    Получение модели и провайдера
    ↓
    Обработка инструментов
    ↓
    Асинхронная генерация чанков
    │
    └── Получение чанка
        │
        ├── Строка? → Добавить в chunks
        │
        ├── Usage?  → Передать дальше
        │
        ├── FinishReason? → Сохранить и прервать
        │
        └── Другое → Передать дальше
    ↓
    Обработка результатов
    ↓
    Завершение
    ↓
    Конец
```

**Примеры**:

```python
# Пример 1: Использование с указанием модели и провайдера
async for chunk in ToolSupportProvider.create_async_generator(model="openai:gpt-4", messages=[{"role": "user", "content": "Hello"}], tools=[{"function": {"name": "get_weather", "parameters": {"properties": {"location": {"type": "string"}}}}}]):
    print(chunk)

# Пример 2: Использование с моделью по умолчанию и указанием инструментов и формата ответа
async for chunk in ToolSupportProvider.create_async_generator(model="gpt-4", messages=[{"role": "user", "content": "What is the weather in London?"}], tools=[{"function": {"name": "get_weather", "parameters": {"properties": {"location": {"type": "string"}}}}}] , response_format={"type": "json"}):
    print(chunk)